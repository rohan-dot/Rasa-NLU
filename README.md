# Rasa-NLU
Interning for convergys I made a chatbot for password reset using rasa-nlu.
I trained the bot for password reset functionalities adding the T-opt service and Lanid of the employee and trained it via own examples to make it's answer seem more human like rather than robotic

Current advancements in Large Language Models (LLMs) have introduced significant challenges in information security, particularly authorship impersonation. This threat involves malicious actors mimicking the writing style of legitimate authors to disseminate false information, conduct influence operations, or compromise sensitive communications. One example is the Chinese government's use of fake personas on social media to influence narratives about the Uyghur population in Xinjiang. These personas spread state-sponsored propaganda, creating a misleading picture of the situation and undermining genuine reports of human rights abuses. Another example is the creation of counterfeit directives within military or government operations, leading to potential operational chaos and security breaches. 

For government entities, the integrity of communications is paramount, making it crucial to develop robust verification systems to protect against such threats. In our research, we perform authorship impersonation using LLMs and Retrieval-Augmented Generation (RAG) techniques to highlight vulnerabilities in current communication systems. We use the PAN 2021 dataset to showcase the ability of LLMs to perform targeted impersonation attacks and utilize various linguistic and stylistic analysis tools to identify discrepancies. Our approach includes the following:

1. **Authorship Verification Models:** We develop and test advanced models to accurately distinguish between legitimate and impersonated texts. This involves training models on diverse datasets to capture a wide range of writing styles and implementing machine learning algorithms to detect subtle stylistic differences.

2. **Evaluation Metrics:** We use performance and linguistic metrics to assess the effectiveness of our models against sophisticated impersonation attempts. This includes precision, recall, and F1 scores, as well as more nuanced linguistic features such as syntax, semantics, and stylistic markers.

3. **Case Studies:** We analyze real-world applications and potential impacts of authorship impersonation on government operations. This includes examining past incidents of impersonation, simulating potential future scenarios, and evaluating the effectiveness of current verification systems.

Our findings reveal significant weaknesses in current authorship verification systems when faced with advanced impersonation techniques using LLMs and RAG. Key results include the following:

- **Model Vulnerabilities:** Existing models often fail to detect subtle stylistic differences introduced by sophisticated impersonation techniques.
- **Need for Robust Systems:** There is a necessity for more advanced and adaptive verification models to effectively counter authorship impersonation.
- **Implications for Security:** There is a potential for widespread misinformation and disruption of command and control (C2) systems if these vulnerabilities are not addressed.

Governments must develop and implement sophisticated authorship verification models to accurately verify communications and prevent impersonation. Military C2 systems need robust authorship verification tools to maintain operational security and effectiveness during crises and conflicts. Protecting the integrity of public communications is essential to prevent misinformation and maintain public confidence in government operations. Sharing knowledge and techniques for authorship verification with allied nations is crucial for creating a unified front against these threats.

By focusing on this issue at the 2024
