If your final output from the chain-of-thought prompt is “too short” or missing important details, there are a few adjustments you can make to encourage the model to reference more information from the context. Here are some practical tips:

---

### 1. Expand the **Chain-of-Thought** Steps

Add an explicit instruction to **exhaustively examine the context** for all relevant facts. For example:

> **Examine the Provided Context:**  
> - **Read through the entire context thoroughly** and identify **all** facts or data points that **directly or indirectly** address the hateful speech.  
> - Include **all** potentially relevant details, 

# Rasa-NLU
Interning for convergys I made a chatbot for password reset using rasa-nlu.
I trained the bot for password reset functionalities adding the T-opt service and Lanid of the employee and trained it via own examples to make it's answer seem more human like rather than robotic


