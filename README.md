# Rasa-NLU
Interning for convergys I made a chatbot for password reset using rasa-nlu.
I trained the bot for password reset functionalities adding the T-opt service and Lanid of the employee and trained it via own examples to make it's answer seem more human like rather than robotic

Hereâ€™s the text rewritten in simpler language without using fancy words:

---

New developments in Large Language Models (LLMs) have brought up big problems in information security, especially with fake authorship. This problem happens when people copy the writing style of real authors to spread false information, influence others, or break into sensitive communications. For example, the Chinese government has used fake accounts on social media to spread propaganda about the Uyghur population in Xinjiang, which creates a false picture and weakens real reports of human rights abuses. For government agencies, keeping their communications trustworthy is very important, so they need strong verification systems to protect against these threats.

In our research, we look at how LLMs and Retrieval-Augmented Generation (RAG) techniques can highlight weaknesses in current communication systems. We use the PAN 2021 dataset to show how LLMs can perform targeted impersonation attacks and use different methods to find differences in writing styles. Our approach includes:

1. **Fake Authorship Models:** We use a two-step method. First, we use an LLM and RAG to get the style of the author we want to mimic. Then, we use this style to write sentences that copy the target's writing.

2. **Authorship Verification Models:** We test advanced models to tell the difference between real and fake texts. This involves training models on the PAN 2021 dataset to learn different writing styles and using deep learning to spot subtle differences.

3. **Evaluation Metrics:** We measure how well our fake authorship model works by looking at the success rate of attacks and using semantic metrics to compare the fake text to the real text.

Our findings show big weaknesses in current authorship verification systems when dealing with advanced fake authorship techniques using LLMs and RAG. Key results include:

- **Model Weaknesses:** Current models often miss small stylistic changes made by advanced fake authorship methods.

- **Need for Better Systems:** There is a need for more advanced and adaptable verification models to effectively fight against fake authorship.

In this talk, we show how LLMs and RAG can perform targeted fake authorship on the PAN 2021 dataset and exploit current verification systems. We also discuss what these findings mean for government security, stressing the need for better and more resilient authorship verification models.

---

This version uses simpler language and avoids fancy words, which should make it less likely to be flagged as AI-generated.
